#!/bin/bash
set -e

usage() {
    echo "Usage: $0 [module] [build type] [phase] <args>"
    echo "-----------------------------"
    echo "module:"
    echo "  all          - all modules"
    echo "  core         - mrgeo-core"
    echo "  vector       - mrgeo-core/mrgeo-vector"
    echo "  mapalgebra   - mrgeo-core/mrgeo-vector/mrgeo-mapalgebra"
    echo "  cmd          - mrgeo-core/mrgeo-vector/mrgeo-cmd"
    echo "  dataprovider - mrgeo-core/mrgeo-dataprovider"
    echo "  services     - mrgeo-core/mrgeo-vector/mrgeo-services"
    echo "  python       - mrgeo-core/mrgeo-vector/mrgeo-dataprovider/mrgeo-mapalgebra/mrgeo-python"
    echo "  ogc          - mrgeo-core/mrgeo-services-(core, wms, wcs, tms)"
    echo "build type:"
    echo "  apache    - apache hadoop"
    echo "  apache272 - Apache hadoop, version 2.7.2"
    echo "  apache271 - Apache hadoop, version 2.7.1"
    echo "  apache260 - Apache hadoop, version 2.6.0"
    echo "  apache252 - Apache hadoop, version 2.5.2"
    echo "  apache251 - Apache hadoop, version 2.5.1"
    echo "  apache250 - Apache hadoop, version 2.5.0"
    echo "  apache241 - Apache hadoop, version 2.4.1"
    echo "  apache240 - Apache hadoop, version 2.4.0"
    echo "  cdh5120   - Cloudera hadoop 5.12.0"
    echo "  cdh5111   - Cloudera hadoop 5.11.1"
    echo "  cdh5110   - Cloudera hadoop 5.11.0"
    echo "  cdh5101   - Cloudera hadoop 5.10.1"
    echo "  cdh5100   - Cloudera hadoop 5.10.0"
    echo "  cdh591    - Cloudera hadoop 5.9.1"
    echo "  cdh590    - Cloudera hadoop 5.9.0"
    echo "  cdh582    - Cloudera hadoop 5.8.2"
    echo "  cdh580    - Cloudera hadoop 5.8.0"
    echo "  cdh571    - Cloudera hadoop 5.7.1"
    echo "  cdh570    - Cloudera hadoop 5.7.0"
    echo "  cdh560    - Cloudera hadoop 5.6.0"
    echo "  cdh552    - Cloudera hadoop 5.5.2"
    echo "  cdh551    - Cloudera hadoop 5.5.1"
    echo "  cdh550    - Cloudera hadoop 5.5.0"
    echo "  emr580 - Amazon EMR 5.8.0 with hadoop 2.7.3"
    echo "  emr530 - Amazon EMR 5.3.0 with hadoop 2.7.3"
    echo "  emr500 - Amazon EMR 5.0.0 with hadoop 2.7.2"
    echo "  emr472 - Amazon EMR 4.7.2 with hadoop 2.7.2"
    echo "  emr471 - Amazon EMR 4.7.1 with hadoop 2.7.2"
    echo "  emr470 - Amazon EMR 4.7.0 with hadoop 2.7.2"
    echo "  emr460 - Amazon EMR 4.6.0 with hadoop 2.7.2"
    echo "  emr450 - Amazon EMR 4.5.0 with hadoop 2.7.2"
    echo "  emr440 - Amazon EMR 4.4.0 with hadoop 2.7.1"
    echo "  mapr      - mapr hadoop"
    echo "phase:"
    echo "  build     - build a deployable version"
    echo "  test      - build, then run unit tests"
    echo "  verify    - run integration tests"
    echo "  deploy    - build and deploy"
    echo "  clean     - clean the build"
    echo "  version   - change the version within all poms (use 'revert' to revert to previously saved version, if any)"
    echo "  eclipse   - build eclipse files for the project"
    echo "args:"
    echo "  -c  --conf <path>              - location of hadoop conf files (/usr/local/hadoop/conf)"
    echo "  -f  --failfast                 - fail fast tests (immediately stop on test failure)"
    echo "  -g  --geowave                  - build the GeoWave data provider"
    echo "  -gj --generate-javadocs        - generate javadoc jars"
    echo "  -gs --generate-sources         - generate source jars"
    echo "  -j  --javadocs                 - include javadocs of dependencies (if available)"
    echo "  -jv  --javaversion <version>   - java version to use (1.7)"
    echo "  -l  --license                  - generate licenses (normall off)"
    echo "  -p  --profile                  - turn on leak detection profiling"
    echo "  -s  --source                   - include source jars of dependencies (if available)"
    echo "  -sh --shade                    - generate the shaded (jar with dependencies) jars"
    echo "  -y  --yarn                     - use hadoop YARN (for hadoop 2+, instead of mr1)"
    echo "  -q  --quiet                    - quiet (no prints from this script)"
    echo "other:"
    echo "  buildtype  - return the build type (apache272, cdh5120, etc.), no further processing is done"
    echo " "
    echo "  all other args will be passed to maven directly"
    echo " "
}

run-eclipse() {

    mvn -Denv=eclipse eclipse:clean $ARGS
    mvn -Denv=eclipse eclipse:eclipse  $ARGS

    # don't need monocle anymore
    # pushd monocle
    # mvn -Denv=eclipse gwt:eclipse $ARGS
    # mvn -Denv=eclipse war:exploded $ARGS
    # popd

    # This find & sed edits the .project file to add resource filters
    # - ignore all .svn files
    find . -name .project -exec sed -i 's|</projectDescription>|\
        <filteredResources>\
          <filter>\
            <id>1345462274799</id>\
            <name />\
            <type>30</type>\
            <matcher>\
              <id>org.eclipse.ui.ide.multiFilter</id>\
              <arguments>1.0-name-matches-false-false-*.svn*</arguments>\
            </matcher>\
          </filter>\
        </filteredResources>\
        </projectDescription>|' {} \;

    # This adds an "exported="true" to the jar libraries, so we can run from eclipse
    find . -name .classpath -exec sed -i 's|kind="var" path="M2_REPO|kind="var" exported="true" path="M2_REPO|' {} \;

    CONF_LINK=`readlink -f $CONF`
    echo $CONF_LINK
    find . -name .classpath -exec sed -i 's|^.*path="'$CONF_LINK'".*|<classpathentry kind="lib" path="'$CONF_LINK'"/>|' {} \;

    # This removes the warning: "Classpath entry M2_REPO/<xxx>.jar will not be exported or published. Runtime ClassNotFoundExceptions may result."
    pushd mrgeo-services/mrgeo-services-distribution
    sed -i '/<classpathentry kind="var"/{s|/>$|><attributes><attribute name="org.eclipse.jst.component.nondependency" value=""\/\></attributes></classpathentry>|}' .classpath

    # This removes the same warning for the CONF param (usually /usr/local/hadoop/conf)
    REPLACED=${CONF//\//\\\/}
    sed  -i "/$REPLACED/{s|/>$|><attributes><attribute name=\"org.eclipse.jst.component.nondependency\" value=\"\"\/\></attributes></classpathentry>|}" .classpath
    popd

}

# for i in $*; do
# echo $i
# done;

PHASE="test"
MODULE="all"
BUILD="apache260"
CONF="/etc/hadoop/conf"
LICENSE="-DskipLicenses"
RELEASEPHASE=prepare

# add any predefined options (for developer convenience)
if [ -n "$MRGEO_BUILD_OPTIONS" ]; then
    set -- $MRGEO_BUILD_OPTIONS "$@"
fi

CWD=`pwd`

ARGS=""

if [ $# -lt 1 ]; then
  usage
  exit 1
fi


SKIPCOREINTEGRATION="-Pskip-core-integration-tests"
SKIPCOREUNIT="-Pskip-core-unit-tests"
SKIPCORE="-Pskip-core-tests"

SKIPVECTORINTEGRATION="-Pskip-vector-integration-tests"
SKIPVECTORUNIT="-Pskip-vector-unit-tests"
SKIPVECTOR="-Pskip-vector-tests"

SKIPMAPALGEBRAINTEGRATION="-Pskip-mapalgebra-integration-tests"
SKIPMAPALGEBRAUNIT="-Pskip-mapalgebra-unit-tests"
SKIPMAPALGEBRA="-Pskip-mapalgebra-tests"

SKIPDPINTEGRATION="-Pskip-dataprovider-integration-tests"
SKIPDPUNIT="-Pskip-dataprovider-unit-tests"
SKIPDP="-Pskip-dataprovider-tests"

SKIPCMDINTEGRATION="-Pskip-cmd-integration-tests"
SKIPCMDUNIT="-Pskip-cmd-unit-tests"
SKIPCMD="-Pskip-cmd-tests"

SKIPSERVICESINTEGRATION="-Pskip-services-integration-tests"
SKIPSERVICESUNIT="-Pskip-services-unit-tests"
SKIPSERVICES="-Pskip-services-tests"

SKIPPYTHONINTEGRATION="-Pskip-python-integration-tests"
SKIPPYTHONUNIT="-Pskip-python-unit-tests"
SKIPPYTHON="-Pskip-python-tests"

SKIPALLINTEGRATION="-Pskip-all-integration-tests"
SKIPALLUNIT="-Pskip-all-unit-tests"
SKIPALL="-Pskip-all-tests"

while [ $# -gt 0 ] ; do
    case $1 in
    "-h" | "--help" | "-?" | "help")
        usage
        exit 0
        ;;
    "buildtype")
        BUILDTYPE="true"
        ;;
    "all")
        MODULE="all"
        ;;
    "core" | "core-only")
        MODULE="core"
        ARGS="$SKIPVECTOR $SKIPDP $SKIPMAPALGEBRA $SKIPCMD $SKIPPYTHON $SKIPSERVICES $ARGS"
        ;;
    "mapalgebra")
        MODULE="mapalgebra"
        ;;
    "mapalgebra-only")
        MODULE="mapalgebra"
        ARGS="$SKIPCORE $SKIPVECTOR $SKIPDP $SKIPCMD $SKIPPYTHON $SKIPSERVICES $ARGS"
        ;;
    "vector")
        MODULE="vector"
        ;;
    "vector-only")
        MODULE="vector"
        ARGS="$SKIPCORE $SKIPDP $SKIPMAPALGEBRA $SKIPCMD $SKIPPYTHON $SKIPSERVICES $ARGS"
        ;;
    "dataprovider")
        MODULE="dataprovider"
        ;;
    "dataprovider-only")
        MODULE="dataprovider"
        ARGS="$SKIPCORE $SKIPVECTOR $SKIPMAPALGEBRA $SKIPCMD $SKIPPYTHON $SKIPSERVICES $ARGS"
        ;;
    "cmd")
        MODULE="cmd"
        ;;
    "cmd-only")
        MODULE="cmd"
        ARGS="$SKIPCORE $SKIPVECTOR $SKIPDP $SKIPMAPALGEBRA $SKIPPYTHON $SKIPSERVICES $ARGS"
        ;;
    "services")
        MODULE="services"
        ;;
    "services-only")
        MODULE="services"
        ARGS="$SKIPCORE $SKIPVECTOR $SKIPDP $SKIPMAPALGEBRA $SKIPCMD $SKIPPYTHON $ARGS"
        ;;
    "python")
        MODULE="python"
        ;;
    "python-only")
        MODULE="python"
        ARGS="$SKIPCORE $SKIPVECTOR $SKIPDP $SKIPMAPALGEBRA $SKIPCMD $SKIPSERVICES $ARGS"
        ;;
    "ogc")
        MODULE="ogc"
        ARGS="$SKIPALL $ARGS"
        ;;
    "apache220" | "apache230" | "apache240" | "apache241" )
        BUILD=$1
        ;;
    "apache250" | "apache251" | "apache252")
        BUILD=$1
        ;;
    "apache260" | "apache270" | "apache271" | "apache272")
        BUILD=$1
        ;;
    "emr580")
        BUILD="emr580"
        ;;
    "emr530")
        BUILD="emr530"
        ;;
    "emr500")
        BUILD="emr500"
        ;;
    "emr472")
        BUILD="emr472"
        ;;
    "emr471")
        BUILD="emr471"
        ;;
    "emr470")
        BUILD="emr470"
        ;;
    "emr460")
        BUILD="emr460"
        ;;
    "emr450")
        BUILD="emr450"
        ;;
    "emr440")
        BUILD="emr440"
        ;;
    "mapr")
        echo "*** MapR Hadoop is no longer supported"
        exit
        ;;
    "cdh550" | "cdh550-yarn" | "cdh551" | "cdh551-yarn" | "cdh552" | "cdh552-yarn")
        BUILD=$1
        ;;
    "cdh560" | "cdh560-yarn")
        BUILD=$1
        ;;
    "cdh570" | "cdh570-yarn" | "cdh571" | "cdh571-yarn")
        BUILD=$1
        ;;
    "cdh580" | "cdh580-yarn" | "cdh582" | "cdh582-yarn")
        BUILD=$1
        ;;
    "cdh590" | "cdh590-yarn" | "cdh591" | "cdh591-yarn")
        BUILD=$1
        ;;
    "cdh5100" | "cdh5100-yarn" | "cdh5101" | "cdh5101-yarn")
        BUILD=$1
        ;;
    "cdh5110" | "cdh5110-yarn")
        BUILD=$1
        ;;
    "cdh5111" | "cdh5111-yarn")
        BUILD=$1
        ;;
    "cdh5120" | "cdh5120-yarn")
        BUILD=$1
        ;;
    "build")
        PHASE="build"
        ;;
    "deploy")
        PHASE="deploy"
        SKIPLICENSE=
        ;;
    "test")
        PHASE="test"
        ;;
    "integration")
        PHASE="integration"
        ;;
    "release")
        PHASE="release"
        if [ $2 == "rollback" ]
        then
          RELEASEPHASE="rollback"
          shift 1
        fi
        ;;
    "verify")
        PHASE="verify"
        ;;
    "version")
        PHASE="version"
        VERSION=$2
        shift 1
        ;;
    "cobertura:cobertura")
        PHASE="cobertura:cobertura"
        ;;
    "clean")
        PHASE="clean"
        ;;
    "eclipse")
        PHASE="eclipse"
        ;;
    "-c" | "--conf")
        ARGS=$ARGS" -Dhadoop-config="$2
        CONF=$2
        shift 1
        ;;
    "-f" | "--failfast")
        ARGS=$ARGS" -Dmrgeo.failfast=true"
        ;;
    "-j" | "--javadocs")
        ARGS=$ARGS" -DdownloadJavadocs=true"
        ;;
    "-p" | "--profile")
        ARGS=$ARGS" -Dmrgeo.profile=true"
        ;;
    "-s" | "--source")
        ARGS=$ARGS" -DdownloadSources=true"
        ;;
    "-jv" | "--javaversion")
        ARGS=$ARGS" -Djava.version="$2
        shift 1
        ;;
    "-y" | "--yarn")
        USEYARN=true
        ;;
    "-q" | "--quiet")
        QUIET="true"
        ;;
    "-g" | "--geowave")
        ARGS=$ARGS" -Pinclude-geowave"
        ;;
    "-gj" | "--generate-javadocs")
        ARGS=$ARGS" -Pgenerate-javadocs"
        ;;
    "-gs" | "--generate-sources")
        ARGS=$ARGS" -Pgenerate-sources"
        ;;
    "-l" | "--license")
        LICENSE=
        ;;
    "-sh" | "--shade")
        ARGS=$ARGS" -Prun-shading"
        ;;
     *)
     ARGS=$ARGS" "$1
      ;;
    esac
    shift 1
done

if [ -n "$BUILDTYPE" ]; then
  echo $BUILD
  exit 0
fi


if [ -n "$USEYARN" ]; then
    if [[ "$BUILD" != *-yarn ]] && [[ "$BUILD" != apache* ]]; then
      BUILD=$BUILD-yarn
    fi
fi

export HOME=$CWD


if [ -z "$QUIET" ]; then
    echo " "
    echo "Phase: " $PHASE
    echo "Module: " $MODULE
    echo " "
    echo "Building for " $BUILD
    echo "-----------------------"
    echo "  JAVA_HOME:           " $JAVA_HOME
    echo "  HADOOP_HOME:         " $HADOOP_HOME
    echo "  HADOOP_PREFIX:       " $HADOOP_PREFIX
    echo "  MRGEO_COMMON_HOME:   " $MRGEO_COMMON_HOME
    echo "  MRGEO_CONF_DIR:      " $MRGEO_CONF_DIR
    echo "  MRGEO_HOME:          " $MRGEO_HOME
    echo "  Build:               " $HOME
    echo " "
    echo "  Additional maven args: " $ARGS
    echo " "
fi

ARGS="-P$BUILD -Dmodules=$MODULE -DfailIfNoTests=false $LICENSE $ARGS"


case $PHASE in
   "build")
       ARGS="$SKIPALL $ARGS"
   ;;
   "deploy")
       ARGS="$SKIPALL $ARGS deploy"
   ;;
   "test")
       ARGS="$SKIPALLINTEGRATION $ARGS"
   ;;
   "integration")
       ARGS="$SKIPALLUNIT $ARGS verify"
   ;;
   "verify")
       ARGS="$ARGS verify"
   ;;
   "version")
       if [ $VERSION == "revert" ]; then
           ARGS="$ARGS versions:revert"
       else
           ARGS="$ARGS versions:set -DnewVersion=$VERSION"
       fi
   ;;
   "release")
       ARGS="$SKIPALL $ARGS"
       ARGS="$ARGS \"-Drelease.arguments=$ARGS\" --batch-mode release:$RELEASEPHASE -DautoVersionSubmodules=true"
   ;;
   "cobertura:cobertura")
       ARGS="$ARGS cobertura:cobertura"
   ;;
   "clean")
       ARGS="$ARGS clean"
   ;;
   "eclipse")
   run-eclipse
   exit 1
   ;;
esac

if [ -z "$QUIET" ]; then
    echo "-----------------------"
    echo "  Maven command: "
    echo "mvn $ARGS"
    echo " "
fi
mvn $ARGS
